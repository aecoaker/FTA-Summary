{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aecoaker/FTA-Summary/blob/master/Exploring_BART_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ5omMGUjzeP"
      },
      "source": [
        "# Exploring BART Models to find best Pre-Trained Option"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyfleaffDXO6"
      },
      "source": [
        "## Example of work prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Btv0UJ7Lj0tE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "dde585224a4b494f97eb41ddcb75ecbc",
            "3ddbb53de5b941e59384db13b05900ed",
            "c4c61a35c3764f9dac5374969efc4b5d",
            "c7607bd64ae04d52823a643b8ea8e057",
            "e8f0adc8c6ed4e498bf444d7ec4b556b",
            "fd4aec807a0d42cd8d1017350e08d000",
            "f1a855ef5d51442fa0c9905c16687f01",
            "60a949a41768424baf091355d04d7176",
            "f12ccf3f82c3462d9cbc70a57d4c8962",
            "5d496d630e894214bb4891924214dfb0",
            "4131bae858f747a5a44f2234cc86bf26",
            "3931f0ee12ae411b888a5996bed27814",
            "38525c8864e8491ab2d29baf0d02e249",
            "0c443811aa2745b6ad17c2ed19cfb9ed",
            "f8d99f4cbcba4610b48b4f34074619f4",
            "1c2150a37dc94c8ca9ce1bb42195f1be",
            "f67e60b3738347ed91ead1c69838d9b5",
            "75852cf562fe438db107f42ff16f058e",
            "84ee0eb73a0a4ca38b908327c495805c",
            "37919a048d6b4c38b2a4c95c31ff48cf",
            "dd9acfd0334e4547b13a62a4f6026496",
            "3a7fe6595155460e9bdbd051aa5657e8",
            "9d9cdbf07e354a52b1aedae6d932132b",
            "bca8b966479a4ddcb687f6b9d7beff2b",
            "2c685a6aa86c4359a10a62ee429b402a",
            "680b8f9716684e0da3a0afebc5278e25",
            "5526ef9a53b44080aadffab58d6351e8",
            "ab913ed970fb4fae8ae67152603ed014",
            "cca71fbe5593442ebb0fb05ab382d477",
            "27ee660d6e014644b949d29bdda63ace",
            "e484403387aa45d1bcc6c1b2cc4cfc17",
            "9f73a9f82974417a90b3308463b12804",
            "83ff25bf5cdb45f6a5445d6f3273aff8",
            "265b34889c2a4fb38847af5707eaebd8",
            "c17aa000212e4455a1a736892f021369",
            "6e615a371b7e4995b4c800fb2a45d7c3",
            "28150e4dff324be49264eb58871c5198",
            "aafb8a0fa7ee45c09bda3a303ad0da78",
            "0c1886311f5349b1b051c0b99ab8947e",
            "bdb619970e13472d993e4be3c97644fd",
            "30f2459433324f36b16108ebf8dfc8d7",
            "71952f636a4642e8a28a8c18439ac160",
            "a595a3a93d9a4708910e8bf8466d9365",
            "25651b06bf5d45309bb43aa3be733a9a"
          ]
        },
        "outputId": "76304241-9f9a-4540-fd89-4428f4426853"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dde585224a4b494f97eb41ddcb75ecbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3931f0ee12ae411b888a5996bed27814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d9cdbf07e354a52b1aedae6d932132b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "265b34889c2a4fb38847af5707eaebd8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n",
        "import statistics\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "# load a pre-trained model and tokenizer 'bart-large-cnn'\n",
        "tokeniser = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPUeaTOuoRqM"
      },
      "outputs": [],
      "source": [
        "text = \"'customs duty reduction or elimination' means any customs duty reduction or elimination\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgRY3Rt6pO5k",
        "outputId": "18482b7a-bfb2-4607-e9a1-0a2235d54cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'customs duty reduction or elimination' means any customs duty collection or elimination\n"
          ]
        }
      ],
      "source": [
        "#use bart for summary of the sentence to check it all works\n",
        "inputs = tokeniser.batch_encode_plus([text],return_tensors='pt')\n",
        "summary_ids = model.generate(inputs['input_ids'], early_stopping=True)\n",
        "bart_summaries = tokeniser.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(bart_summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37zGGt-pRZv-"
      },
      "outputs": [],
      "source": [
        "#create text with a masked word\n",
        "text = \"'customs duty reduction or elimination' means any customs duty <mask> or elimination\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDZ6OSt9-P_5",
        "outputId": "9781b38d-80b3-47d0-d13f-c7d234369c75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['reduction', 'reductions', 'cut', 'increase', 'reduced']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#now use BART to predict what the word is\n",
        "input_ids = tokeniser([text], return_tensors=\"pt\")[\"input_ids\"]\n",
        "logits = model(input_ids).logits\n",
        "masked_index = (input_ids[0] == tokeniser.mask_token_id).nonzero().item()\n",
        "probs = logits[0, masked_index].softmax(dim=0)\n",
        "values, predictions = probs.topk(5) #only get top 5 predictions\n",
        "tokeniser.decode(predictions).split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD9iSzaCDqqx"
      },
      "source": [
        "## Writing this into a function that generates a metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv_YvIHVDuGb"
      },
      "outputs": [],
      "source": [
        "def perplexity(text, model = 'facebook/bart-base'):\n",
        "  #read in chosen model and set up empty lists to use\n",
        "  tokeniser = BartTokenizer.from_pretrained(model)\n",
        "  model = BartForConditionalGeneration.from_pretrained(model)\n",
        "  prod__pp_t = 1\n",
        "  calculated_probs = []\n",
        "  #tokenise text to get its length\n",
        "  input_ids = tokeniser([text], return_tensors=\"pt\")[\"input_ids\"]\n",
        "  n = len(input_ids[0])\n",
        "  #iterate through tokens\n",
        "  for i in range(1, n):\n",
        "    #get full set of inputs, find real value then replace token with '<mask>'\n",
        "    input_ids = tokeniser([text], return_tensors=\"pt\")[\"input_ids\"]\n",
        "    true_token = int(input_ids[0][i])\n",
        "    input_ids[0][i] = 50264\n",
        "    #find sliding window of tokens to use as context\n",
        "    if n < 1024:\n",
        "      window_start = 0\n",
        "      window_end = n\n",
        "    else:\n",
        "      window_start = i - 512\n",
        "      window_end = i + 512\n",
        "    if window_start < 0:\n",
        "      window_start = 0\n",
        "      window_end += -(i - 512)\n",
        "    if window_end > n:\n",
        "      window_end = n\n",
        "      window_start += -(n - i - 512)\n",
        "    #subset the input_ids to only look at the sliding window\n",
        "    input_ids = input_ids[:, window_start:window_end]\n",
        "    #use BART to predict what this token is given the context in the window\n",
        "    logits = model(input_ids).logits\n",
        "    masked_index = (input_ids[0] == tokeniser.mask_token_id).nonzero().item()\n",
        "    probs = logits[0, masked_index].softmax(dim=0)\n",
        "    values, predictions = probs.topk(1000)\n",
        "    #get the probability of the true token within this prediction\n",
        "    try:\n",
        "      true_token_index = predictions.tolist().index(true_token)\n",
        "      true_token_prob = values[true_token_index].detach().numpy().item()\n",
        "    #deal with words that aren't in the top 1000 predictions by assigning them a very small probability\n",
        "    except:\n",
        "      true_token_prob = 0.00000000001\n",
        "    #calculate the reciprocals of the probabilities and multiple together\n",
        "    calculated_probs.append(true_token_prob)\n",
        "    pp_t = 1/true_token_prob\n",
        "    prod__pp_t *= pp_t\n",
        "  #calculate the perplexity by normalising this, also (for comparison) show avg probabilities\n",
        "  perplexity = prod__pp_t ** (1/n)\n",
        "  print(perplexity)\n",
        "  print(statistics.mean(calculated_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yStUTHYVz-R",
        "outputId": "3abb1c25-22e6-444d-d3f0-25a574e6c018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.062052423780026\n",
            "0.3582747515974616\n"
          ]
        }
      ],
      "source": [
        "text = \"After receipt by a Party's investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. \"\n",
        "start = time.perf_counter()\n",
        "perplexity(text)\n",
        "end = time.perf_counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTOSD6nvoGzM",
        "outputId": "4ab26432-8247-4f76-e9e5-eaef336327dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text had 51 words and this took 15.918545544999972 seconds to run\n"
          ]
        }
      ],
      "source": [
        "print('The text had ' + str(len(text.split())) + ' words and this took ' + str(end - start) + ' seconds to run')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore for the full FTA (over 100,000 words), it would take more than 8 hours to calculate the perplexity (longer when you consider that tokenising a full 1024 token sliding window to get the context will take longer than doing so for 51 words)."
      ],
      "metadata": {
        "id": "Hg9-X0pXlJzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#re-writing function to sample a window from the text (not a sliding window)\n",
        "#we will use that instead of the full text in order to allow us to measure for FTAs\n",
        "def perplexity(text, model = 'facebook/bart-base'):\n",
        "  #read in chosen model and set up empty lists to use\n",
        "  tokeniser = BartTokenizer.from_pretrained(model)\n",
        "  model = BartForConditionalGeneration.from_pretrained(model)\n",
        "  prod__pp_t = 1\n",
        "  all_probs = []\n",
        "  #tokenise text to get its length\n",
        "  input_ids = tokeniser([text], return_tensors=\"pt\")[\"input_ids\"]\n",
        "  n = len(input_ids[0])\n",
        "  #randomly select a window in which we will consider the perplexity\n",
        "  m = 600\n",
        "  if n > m:\n",
        "    window_start = random.sample(range(0, n - m), 1)[0]\n",
        "    window_end = window_start + m\n",
        "  else:\n",
        "    window_start = 0\n",
        "    window_end = n\n",
        "  #get tokens for this window only\n",
        "  input_ids = input_ids[:, window_start:window_end]\n",
        "  #iterate through tokens in this window only\n",
        "  for i in range(0, window_end - window_start):\n",
        "    #find real value then replace its token with '<mask>'\n",
        "    input_ids_to_mask = copy.deepcopy(input_ids) #copy tokens instead of re-generating each loop\n",
        "    true_token = int(input_ids_to_mask[0][i])\n",
        "    input_ids_to_mask[0][i] = 50264\n",
        "    #use BART to predict what this token is given the context in the window\n",
        "    logits = model(input_ids_to_mask).logits\n",
        "    masked_index = (input_ids_to_mask[0] == tokeniser.mask_token_id).nonzero().item()\n",
        "    probs = logits[0, masked_index].softmax(dim=0)\n",
        "    values, predictions = probs.topk(1000)\n",
        "    #get the probability of the true token within this prediction\n",
        "    try:\n",
        "      true_token_index = predictions.tolist().index(true_token)\n",
        "      true_token_prob = values[true_token_index].detach().numpy().item()\n",
        "    #deal with words that aren't in the top 1000 predictions by assigning them a very small probability\n",
        "    except:\n",
        "      true_token_prob = 0.00001\n",
        "    #calculate the reciprocals of the probabilities and multiple together\n",
        "    all_probs.append(true_token_prob)\n",
        "    pp_t = 1.0/true_token_prob\n",
        "    prod__pp_t *= pp_t\n",
        "  #calculate the perplexity by normalising this, also (for comparison) show avg probabilities\n",
        "  perplexity = prod__pp_t ** (1.0/(window_end - window_start))\n",
        "  print('The perplexity of this model applies to the text was ' + str(perplexity))\n",
        "  print('This came from an average probability of the masked token being: ' + str(statistics.mean(all_probs)))"
      ],
      "metadata": {
        "id": "HeYu0t-x8XAP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check this still works as expected for smaller blocks of text\n",
        "text = \"After receipt by a Party's investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. \"\n",
        "perplexity(text)"
      ],
      "metadata": {
        "id": "wlBY3k2ZAU9f",
        "outputId": "829e2cc0-30de-4c7e-89dd-ec616ce36144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The perplexity of this model applies to the text was 15.062052955338832\n",
            "This came from an average probability of the masked token being: 0.3686250351319093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test on a large block of text\n",
        "text = 'For the purposes of this Chapter: “bilateral safeguard measure” means a measure referred to in paragraph 2 of Article 3.6 (Application of a Bilateral Safeguard Measure); “customs duty reduction or elimination” means any customs duty reduction or elimination in accordance with paragraph 2 of Article 2.5 (Treatment of Customs Duties – Trade in Goods); “domestic industry” means, with respect to an imported good, the producers as a whole of the like or directly competitive good operating within the territory of a Party, or those whose collective output of the like or directly competitive good constitutes a major proportion of the total domestic production of the good; “serious injury” means a significant overall impairment in the position of a domestic industry; “threat of serious injury” means serious injury that is clearly imminent, in accordance with the provisions of Article 3.8 (Investigation Procedure). A determination of the existence of a threat of serious injury shall be based on facts and not merely on allegation, conjecture, or remote possibility; and “transition period” means, in relation to a good, the entry into force of this Agreement until five years after the completion of the customs duty reduction or elimination in relation to the good. After receipt by a Party’s investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. 2. Without prejudice to its other rights and obligations under the SCM Agreement, prior to initiating a countervailing duty investigation against imports from the other Party, the importing Party shall afford to the other Party a reasonable opportunity to consult with the aim of clarifying the situation on matters raised in the application and arriving at a mutually agreed solution. Any such consultations shall not unnecessarily delay or prevent a Party from proceeding expeditiously to initiate and conduct an investigation. 3. The Parties reaffirm their rights and obligations under Articles 6.2 and 6.3 of the AD Agreement and Article 12.2 of the SCM Agreement, including with respect to the rights of interested parties to present information orally and to defend their interests in the conduct of an anti-dumping investigation or a countervailing duty investigation. 4. Each Party shall ensure, before a final determination is made, full and meaningful disclosure of all essential facts under consideration which form the basis for the decision whether to apply definitive measures in an anti-dumping investigation or a countervailing duty investigation. This is without prejudice to Article 6.5 of the AD Agreement and Article 12.4 of the SCM Agreement. Disclosures shall be made in writing, and allow interested parties sufficient time to defend their interests. For the purposes of this Chapter: “bilateral safeguard measure” means a measure referred to in paragraph 2 of Article 3.6 (Application of a Bilateral Safeguard Measure); “customs duty reduction or elimination” means any customs duty reduction or elimination in accordance with paragraph 2 of Article 2.5 (Treatment of Customs Duties – Trade in Goods); “domestic industry” means, with respect to an imported good, the producers as a whole of the like or directly competitive good operating within the territory of a Party, or those whose collective output of the like or directly competitive good constitutes a major proportion of the total domestic production of the good; “serious injury” means a significant overall impairment in the position of a domestic industry; “threat of serious injury” means serious injury that is clearly imminent, in accordance with the provisions of Article 3.8 (Investigation Procedure). A determination of the existence of a threat of serious injury shall be based on facts and not merely on allegation, conjecture, or remote possibility; and “transition period” means, in relation to a good, the entry into force of this Agreement until five years after the completion of the customs duty reduction or elimination in relation to the good. After receipt by a Party’s investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. 2. Without prejudice to its other rights and obligations under the SCM Agreement, prior to initiating a countervailing duty investigation against imports from the other Party, the importing Party shall afford to the other Party a reasonable opportunity to consult with the aim of clarifying the situation on matters raised in the application and arriving at a mutually agreed solution. Any such consultations shall not unnecessarily delay or prevent a Party from proceeding expeditiously to initiate and conduct an investigation. 3. The Parties reaffirm their rights and obligations under Articles 6.2 and 6.3 of the AD Agreement and Article 12.2 of the SCM Agreement, including with respect to the rights of interested parties to present information orally and to defend their interests in the conduct of an anti-dumping investigation or a countervailing duty investigation. 4. Each Party shall ensure, before a final determination is made, full and meaningful disclosure of all essential facts under consideration which form the basis for the decision whether to apply definitive measures in an anti-dumping investigation or a countervailing duty investigation. This is without prejudice to Article 6.5 of the AD Agreement and Article 12.4 of the SCM Agreement. Disclosures shall be made in writing, and allow interested parties sufficient time to defend their interests. For the purposes of this Chapter: “bilateral safeguard measure” means a measure referred to in paragraph 2 of Article 3.6 (Application of a Bilateral Safeguard Measure); “customs duty reduction or elimination” means any customs duty reduction or elimination in accordance with paragraph 2 of Article 2.5 (Treatment of Customs Duties – Trade in Goods); “domestic industry” means, with respect to an imported good, the producers as a whole of the like or directly competitive good operating within the territory of a Party, or those whose collective output of the like or directly competitive good constitutes a major proportion of the total domestic production of the good; “serious injury” means a significant overall impairment in the position of a domestic industry; “threat of serious injury” means serious injury that is clearly imminent, in accordance with the provisions of Article 3.8 (Investigation Procedure). A determination of the existence of a threat of serious injury shall be based on facts and not merely on allegation, conjecture, or remote possibility; and “transition period” means, in relation to a good, the entry into force of this Agreement until five years after the completion of the customs duty reduction or elimination in relation to the good. After receipt by a Party’s investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. 2. Without prejudice to its other rights and obligations under the SCM Agreement, prior to initiating a countervailing duty investigation against imports from the other Party, the importing Party shall afford to the other Party a reasonable opportunity to consult with the aim of clarifying the situation on matters raised in the application and arriving at a mutually agreed solution. Any such consultations shall not unnecessarily delay or prevent a Party from proceeding expeditiously to initiate and conduct an investigation. 3. The Parties reaffirm their rights and obligations under Articles 6.2 and 6.3 of the AD Agreement and Article 12.2 of the SCM Agreement, including with respect to the rights of interested parties to present information orally and to defend their interests in the conduct of an anti-dumping investigation or a countervailing duty investigation. 4. Each Party shall ensure, before a final determination is made, full and meaningful disclosure of all essential facts under consideration which form the basis for the decision whether to apply definitive measures in an anti-dumping investigation or a countervailing duty investigation. This is without prejudice to Article 6.5 of the AD Agreement and Article 12.4 of the SCM Agreement. Disclosures shall be made in writing, and allow interested parties sufficient time to defend their interests.'\n",
        "start = time.perf_counter()perplexity(text)\n",
        "end = time.perf_counter()"
      ],
      "metadata": {
        "id": "OHTLsD0nAcMf",
        "outputId": "d38f0c18-52a9-4005-edb4-999bac84c4fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The perplexity of this model applies to the text was inf\n",
            "This came from an average probability of the masked token being: 0.4995486419245062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The text had ' + str(len(text.split())) + ' words and this took ' + str(end - start) + ' seconds to run')"
      ],
      "metadata": {
        "id": "9eKzWJ8dBkOj",
        "outputId": "268f067d-67da-4862-cbe5-21eb68413d55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text had 1383 words and this took 3990.754820027998 seconds to run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite reducing the window from 1024 to 600 tokens (original run not shown) the perplexity is infinite. This is not because of a normalisation problem but because the number being output is too small and Python is rounding it to zero. How large a window can we use before this ceases to be a problem?"
      ],
      "metadata": {
        "id": "p6v_WC56qOup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#re-writing function to sample a window from the text\n",
        "#we will use that instead of the full text in order to allow us to measure for FTAs\n",
        "def perplexity(text, window = 10, model = 'facebook/bart-base'):\n",
        "  #read in chosen model and set up empty lists to use\n",
        "  tokeniser = BartTokenizer.from_pretrained(model)\n",
        "  model = BartForConditionalGeneration.from_pretrained(model)\n",
        "  prod__pp_t = 1\n",
        "  all_probs = []\n",
        "  #tokenise text to get its length\n",
        "  input_ids = tokeniser([text], return_tensors=\"pt\")[\"input_ids\"]\n",
        "  n = len(input_ids[0])\n",
        "  #randomly select a window in which we will consider the perplexity\n",
        "  if n > window:\n",
        "    window_start = random.sample(range(0, n - window), 1)[0]\n",
        "    window_end = window_start + window\n",
        "  else:\n",
        "    window_start = 0\n",
        "    window_end = n\n",
        "  #get tokens for this window only\n",
        "  input_ids = input_ids[:, window_start:window_end]\n",
        "  #iterate through tokens in this window only\n",
        "  for i in range(0, window_end - window_start):\n",
        "    #find real value then replace its token with '<mask>'\n",
        "    input_ids_to_mask = copy.deepcopy(input_ids) #copy tokens instead of re-generating each loop\n",
        "    true_token = int(input_ids_to_mask[0][i])\n",
        "    input_ids_to_mask[0][i] = 50264\n",
        "    #use BART to predict what this token is given the context in the window\n",
        "    logits = model(input_ids_to_mask).logits\n",
        "    masked_index = (input_ids_to_mask[0] == tokeniser.mask_token_id).nonzero().item()\n",
        "    probs = logits[0, masked_index].softmax(dim=0)\n",
        "    values, predictions = probs.topk(1000)\n",
        "    #get the probability of the true token within this prediction\n",
        "    try:\n",
        "      true_token_index = predictions.tolist().index(true_token)\n",
        "      true_token_prob = values[true_token_index].detach().numpy().item()\n",
        "    #deal with words that aren't in the top 1000 predictions by assigning them a very small probability\n",
        "    except:\n",
        "      true_token_prob = 0.00001\n",
        "    #calculate the reciprocals of the probabilities and multiple together\n",
        "    all_probs.append(true_token_prob)\n",
        "    pp_t = 1.0/true_token_prob\n",
        "    prod__pp_t *= pp_t\n",
        "  #calculate the perplexity by normalising this, also (for comparison) show avg probabilities\n",
        "  perplexity = prod__pp_t ** (1.0/(window_end - window_start))\n",
        "  return perplexity"
      ],
      "metadata": {
        "id": "RiL9s5XnqfqD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test on a large block of text with a value of m\n",
        "text = 'For the purposes of this Chapter: “bilateral safeguard measure” means a measure referred to in paragraph 2 of Article 3.6 (Application of a Bilateral Safeguard Measure); “customs duty reduction or elimination” means any customs duty reduction or elimination in accordance with paragraph 2 of Article 2.5 (Treatment of Customs Duties – Trade in Goods); “domestic industry” means, with respect to an imported good, the producers as a whole of the like or directly competitive good operating within the territory of a Party, or those whose collective output of the like or directly competitive good constitutes a major proportion of the total domestic production of the good; “serious injury” means a significant overall impairment in the position of a domestic industry; “threat of serious injury” means serious injury that is clearly imminent, in accordance with the provisions of Article 3.8 (Investigation Procedure). A determination of the existence of a threat of serious injury shall be based on facts and not merely on allegation, conjecture, or remote possibility; and “transition period” means, in relation to a good, the entry into force of this Agreement until five years after the completion of the customs duty reduction or elimination in relation to the good. After receipt by a Party’s investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. 2. Without prejudice to its other rights and obligations under the SCM Agreement, prior to initiating a countervailing duty investigation against imports from the other Party, the importing Party shall afford to the other Party a reasonable opportunity to consult with the aim of clarifying the situation on matters raised in the application and arriving at a mutually agreed solution. Any such consultations shall not unnecessarily delay or prevent a Party from proceeding expeditiously to initiate and conduct an investigation. 3. The Parties reaffirm their rights and obligations under Articles 6.2 and 6.3 of the AD Agreement and Article 12.2 of the SCM Agreement, including with respect to the rights of interested parties to present information orally and to defend their interests in the conduct of an anti-dumping investigation or a countervailing duty investigation. 4. Each Party shall ensure, before a final determination is made, full and meaningful disclosure of all essential facts under consideration which form the basis for the decision whether to apply definitive measures in an anti-dumping investigation or a countervailing duty investigation. This is without prejudice to Article 6.5 of the AD Agreement and Article 12.4 of the SCM Agreement. Disclosures shall be made in writing, and allow interested parties sufficient time to defend their interests. For the purposes of this Chapter: “bilateral safeguard measure” means a measure referred to in paragraph 2 of Article 3.6 (Application of a Bilateral Safeguard Measure); “customs duty reduction or elimination” means any customs duty reduction or elimination in accordance with paragraph 2 of Article 2.5 (Treatment of Customs Duties – Trade in Goods); “domestic industry” means, with respect to an imported good, the producers as a whole of the like or directly competitive good operating within the territory of a Party, or those whose collective output of the like or directly competitive good constitutes a major proportion of the total domestic production of the good; “serious injury” means a significant overall impairment in the position of a domestic industry; “threat of serious injury” means serious injury that is clearly imminent, in accordance with the provisions of Article 3.8 (Investigation Procedure). A determination of the existence of a threat of serious injury shall be based on facts and not merely on allegation, conjecture, or remote possibility; and “transition period” means, in relation to a good, the entry into force of this Agreement until five years after the completion of the customs duty reduction or elimination in relation to the good. After receipt by a Party’s investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. 2. Without prejudice to its other rights and obligations under the SCM Agreement, prior to initiating a countervailing duty investigation against imports from the other Party, the importing Party shall afford to the other Party a reasonable opportunity to consult with the aim of clarifying the situation on matters raised in the application and arriving at a mutually agreed solution. Any such consultations shall not unnecessarily delay or prevent a Party from proceeding expeditiously to initiate and conduct an investigation. 3. The Parties reaffirm their rights and obligations under Articles 6.2 and 6.3 of the AD Agreement and Article 12.2 of the SCM Agreement, including with respect to the rights of interested parties to present information orally and to defend their interests in the conduct of an anti-dumping investigation or a countervailing duty investigation. 4. Each Party shall ensure, before a final determination is made, full and meaningful disclosure of all essential facts under consideration which form the basis for the decision whether to apply definitive measures in an anti-dumping investigation or a countervailing duty investigation. This is without prejudice to Article 6.5 of the AD Agreement and Article 12.4 of the SCM Agreement. Disclosures shall be made in writing, and allow interested parties sufficient time to defend their interests. For the purposes of this Chapter: “bilateral safeguard measure” means a measure referred to in paragraph 2 of Article 3.6 (Application of a Bilateral Safeguard Measure); “customs duty reduction or elimination” means any customs duty reduction or elimination in accordance with paragraph 2 of Article 2.5 (Treatment of Customs Duties – Trade in Goods); “domestic industry” means, with respect to an imported good, the producers as a whole of the like or directly competitive good operating within the territory of a Party, or those whose collective output of the like or directly competitive good constitutes a major proportion of the total domestic production of the good; “serious injury” means a significant overall impairment in the position of a domestic industry; “threat of serious injury” means serious injury that is clearly imminent, in accordance with the provisions of Article 3.8 (Investigation Procedure). A determination of the existence of a threat of serious injury shall be based on facts and not merely on allegation, conjecture, or remote possibility; and “transition period” means, in relation to a good, the entry into force of this Agreement until five years after the completion of the customs duty reduction or elimination in relation to the good. After receipt by a Party’s investigating authority of a properly documented application for an anti-dumping investigation or a countervailing duty investigation with respect to imports from the other Party and before initiating an investigation, the importing Party shall provide written notification to the other Party of its receipt of the application. 2. Without prejudice to its other rights and obligations under the SCM Agreement, prior to initiating a countervailing duty investigation against imports from the other Party, the importing Party shall afford to the other Party a reasonable opportunity to consult with the aim of clarifying the situation on matters raised in the application and arriving at a mutually agreed solution. Any such consultations shall not unnecessarily delay or prevent a Party from proceeding expeditiously to initiate and conduct an investigation. 3. The Parties reaffirm their rights and obligations under Articles 6.2 and 6.3 of the AD Agreement and Article 12.2 of the SCM Agreement, including with respect to the rights of interested parties to present information orally and to defend their interests in the conduct of an anti-dumping investigation or a countervailing duty investigation. 4. Each Party shall ensure, before a final determination is made, full and meaningful disclosure of all essential facts under consideration which form the basis for the decision whether to apply definitive measures in an anti-dumping investigation or a countervailing duty investigation. This is without prejudice to Article 6.5 of the AD Agreement and Article 12.4 of the SCM Agreement. Disclosures shall be made in writing, and allow interested parties sufficient time to defend their interests.'\n",
        "start = time.perf_counter()\n",
        "perplexity(text = text, window = 10)\n",
        "end = time.perf_counter()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y98y4lbKqtwi",
        "outputId": "1f0715b0-578e-44ec-a2c9-e8a47b07e97a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The perplexity of this model applies to the text was 860.5363492048031\n",
            "This came from an average probability of the masked token being: 0.08420456567153754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windows = range(1,500)\n",
        "p = []\n",
        "for w in windows:\n",
        "  p.append(perplexity(text, window = w))"
      ],
      "metadata": {
        "id": "21R7ebKY9Va9",
        "outputId": "2b5be04b-c6f1-4245-b722-ecdc4041392b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-a8c653f908df>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-106849aa118e>\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(text, window, model)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0minput_ids_to_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50264\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#use BART to predict what this token is given the context in the window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_to_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmasked_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids_to_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokeniser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 )\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 )\n\u001b[1;32m   1117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1119\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[1;32m    448\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# cross_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_value_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_value_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# reuse k, v, self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(p)"
      ],
      "metadata": {
        "id": "cYkK5Ij1ja0-",
        "outputId": "aa0f0e33-a22c-4c0c-b116-b9f35f5c3b33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(windows[5:151], p[5:])\n",
        "plt.title('Perplexity for different Window Sizes')\n",
        "plt.xlabel('Window Size')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ElcAoC7396s8",
        "outputId": "cd1ad828-aa56-4a4c-ad3e-bce11e42c1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNg4yd4BTIvRRLE8jL1wO3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dde585224a4b494f97eb41ddcb75ecbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ddbb53de5b941e59384db13b05900ed",
              "IPY_MODEL_c4c61a35c3764f9dac5374969efc4b5d",
              "IPY_MODEL_c7607bd64ae04d52823a643b8ea8e057"
            ],
            "layout": "IPY_MODEL_e8f0adc8c6ed4e498bf444d7ec4b556b"
          }
        },
        "3ddbb53de5b941e59384db13b05900ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd4aec807a0d42cd8d1017350e08d000",
            "placeholder": "​",
            "style": "IPY_MODEL_f1a855ef5d51442fa0c9905c16687f01",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "c4c61a35c3764f9dac5374969efc4b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a949a41768424baf091355d04d7176",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f12ccf3f82c3462d9cbc70a57d4c8962",
            "value": 898823
          }
        },
        "c7607bd64ae04d52823a643b8ea8e057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d496d630e894214bb4891924214dfb0",
            "placeholder": "​",
            "style": "IPY_MODEL_4131bae858f747a5a44f2234cc86bf26",
            "value": " 899k/899k [00:00&lt;00:00, 3.69MB/s]"
          }
        },
        "e8f0adc8c6ed4e498bf444d7ec4b556b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4aec807a0d42cd8d1017350e08d000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a855ef5d51442fa0c9905c16687f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60a949a41768424baf091355d04d7176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12ccf3f82c3462d9cbc70a57d4c8962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d496d630e894214bb4891924214dfb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4131bae858f747a5a44f2234cc86bf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3931f0ee12ae411b888a5996bed27814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38525c8864e8491ab2d29baf0d02e249",
              "IPY_MODEL_0c443811aa2745b6ad17c2ed19cfb9ed",
              "IPY_MODEL_f8d99f4cbcba4610b48b4f34074619f4"
            ],
            "layout": "IPY_MODEL_1c2150a37dc94c8ca9ce1bb42195f1be"
          }
        },
        "38525c8864e8491ab2d29baf0d02e249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f67e60b3738347ed91ead1c69838d9b5",
            "placeholder": "​",
            "style": "IPY_MODEL_75852cf562fe438db107f42ff16f058e",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "0c443811aa2745b6ad17c2ed19cfb9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ee0eb73a0a4ca38b908327c495805c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37919a048d6b4c38b2a4c95c31ff48cf",
            "value": 456318
          }
        },
        "f8d99f4cbcba4610b48b4f34074619f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd9acfd0334e4547b13a62a4f6026496",
            "placeholder": "​",
            "style": "IPY_MODEL_3a7fe6595155460e9bdbd051aa5657e8",
            "value": " 456k/456k [00:00&lt;00:00, 25.6MB/s]"
          }
        },
        "1c2150a37dc94c8ca9ce1bb42195f1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67e60b3738347ed91ead1c69838d9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75852cf562fe438db107f42ff16f058e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84ee0eb73a0a4ca38b908327c495805c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37919a048d6b4c38b2a4c95c31ff48cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd9acfd0334e4547b13a62a4f6026496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7fe6595155460e9bdbd051aa5657e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d9cdbf07e354a52b1aedae6d932132b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bca8b966479a4ddcb687f6b9d7beff2b",
              "IPY_MODEL_2c685a6aa86c4359a10a62ee429b402a",
              "IPY_MODEL_680b8f9716684e0da3a0afebc5278e25"
            ],
            "layout": "IPY_MODEL_5526ef9a53b44080aadffab58d6351e8"
          }
        },
        "bca8b966479a4ddcb687f6b9d7beff2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab913ed970fb4fae8ae67152603ed014",
            "placeholder": "​",
            "style": "IPY_MODEL_cca71fbe5593442ebb0fb05ab382d477",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "2c685a6aa86c4359a10a62ee429b402a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ee660d6e014644b949d29bdda63ace",
            "max": 1716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e484403387aa45d1bcc6c1b2cc4cfc17",
            "value": 1716
          }
        },
        "680b8f9716684e0da3a0afebc5278e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f73a9f82974417a90b3308463b12804",
            "placeholder": "​",
            "style": "IPY_MODEL_83ff25bf5cdb45f6a5445d6f3273aff8",
            "value": " 1.72k/1.72k [00:00&lt;00:00, 134kB/s]"
          }
        },
        "5526ef9a53b44080aadffab58d6351e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab913ed970fb4fae8ae67152603ed014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca71fbe5593442ebb0fb05ab382d477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27ee660d6e014644b949d29bdda63ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e484403387aa45d1bcc6c1b2cc4cfc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f73a9f82974417a90b3308463b12804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ff25bf5cdb45f6a5445d6f3273aff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "265b34889c2a4fb38847af5707eaebd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c17aa000212e4455a1a736892f021369",
              "IPY_MODEL_6e615a371b7e4995b4c800fb2a45d7c3",
              "IPY_MODEL_28150e4dff324be49264eb58871c5198"
            ],
            "layout": "IPY_MODEL_aafb8a0fa7ee45c09bda3a303ad0da78"
          }
        },
        "c17aa000212e4455a1a736892f021369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c1886311f5349b1b051c0b99ab8947e",
            "placeholder": "​",
            "style": "IPY_MODEL_bdb619970e13472d993e4be3c97644fd",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "6e615a371b7e4995b4c800fb2a45d7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f2459433324f36b16108ebf8dfc8d7",
            "max": 557771387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71952f636a4642e8a28a8c18439ac160",
            "value": 557771387
          }
        },
        "28150e4dff324be49264eb58871c5198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a595a3a93d9a4708910e8bf8466d9365",
            "placeholder": "​",
            "style": "IPY_MODEL_25651b06bf5d45309bb43aa3be733a9a",
            "value": " 558M/558M [00:01&lt;00:00, 295MB/s]"
          }
        },
        "aafb8a0fa7ee45c09bda3a303ad0da78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1886311f5349b1b051c0b99ab8947e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb619970e13472d993e4be3c97644fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f2459433324f36b16108ebf8dfc8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71952f636a4642e8a28a8c18439ac160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a595a3a93d9a4708910e8bf8466d9365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25651b06bf5d45309bb43aa3be733a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}